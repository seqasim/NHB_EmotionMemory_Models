{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89921b81-06ad-4757-8349-56998e1d31b1",
   "metadata": {},
   "source": [
    "This will be my notebook for conducting speedy Bayesian mixed-effects logistic regression.\n",
    "\n",
    "\n",
    "Notes\n",
    "___\n",
    "\n",
    "\n",
    "- Bambi needs update xarray (for 'unify_chunks' method), while the data I pickled used xarray 0.13.0 \n",
    "\n",
    "\n",
    "- Bambi can't multi-process sampling across multiple chains if you import joblib, so need to make sure to only load in csv data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89f70c3-f2ac-49d9-93d0-6b592fea3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import argparse\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from Bayesian_model_utils import run_model, plot_res, print_latex_table, plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8087f992-3f27-4713-8e6a-af02f9b726a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n"
     ]
    }
   ],
   "source": [
    "# Make a graphical model of the neural stuff\n",
    "# Model 4: Examine the effect of HFA power and word features on recall. \n",
    "\n",
    "# pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED.csv')\n",
    "pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_ELEC_RESOLVED.csv')\n",
    "pow_df = pow_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# rename the electrodes to properly do the elec random effects \n",
    "pow_df.elec = pow_df.apply(lambda x: f'{x.subj}_{x.elec}', axis=1)\n",
    "\n",
    "# # average across electrodes in a region(subj/region/hemi/ybin) but keep words (arousal/valence/memory) (for speed!)\n",
    "# pow_df = pow_df.groupby(['arousal','valence','subj','region','hemi', 'memory', 'band']).mean().reset_index()\n",
    "\n",
    "# De-mean the valence  \n",
    "pow_df['valence'] = pow_df['valence'] - 0.5\n",
    "\n",
    "# Set categorical orders \n",
    "\n",
    "cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "pow_df.hemi = pow_df.hemi.astype(cat_type)\n",
    "\n",
    "# Let's do separate models for band\n",
    "\n",
    "for band in ['hfa']:\n",
    "        \n",
    "    pow_df = pow_df[pow_df.band==band]\n",
    "\n",
    "    y = 'memory'\n",
    "    X = ['arousal', 'valence', 'region', 'power', 'hemi'] \n",
    "    Intx = ['arousal:valence',\n",
    "            'power:arousal', \n",
    "            'power:valence',\n",
    "            'power:hemi',\n",
    "            'power:region',\n",
    "            'power:region:hemi',\n",
    "            'power:arousal:hemi',\n",
    "            'power:valence:hemi',\n",
    "            'power:arousal:valence',\n",
    "            'power:arousal:region', \n",
    "            'power:valence:region']\n",
    "\n",
    "    label = (f\"{y}\" + \"_{}\"*len(X)).format(*X) + f'_{band}' + 'elec_rand_effect'\n",
    "\n",
    "#             'power:hemi:region:arousal',\n",
    "#             'power:hemi:region:CV'\n",
    "    rand_effect = ['subj', 'elec']\n",
    "    categorical = ['hemi', 'region']\n",
    "\n",
    "    # Drop nan data\n",
    "    pow_df = pow_df.dropna(subset=X)\n",
    "    \n",
    "    rand_term = [f'(1|{x})' for x in rand_effect]\n",
    "    formula = f'{y} ~ 1+'+'+'.join(rand_term)+'+'+'+'.join(X)+'+'+'+'.join(Intx)\n",
    "    model_fam = 'bernoulli'\n",
    "    priors=None\n",
    "    categorical=None\n",
    "    # construct the model \n",
    "    model = bmb.Model(formula=formula, \n",
    "                  data=pow_df[rand_effect + [y] + X],\n",
    "                 family=model_fam,\n",
    "                 priors=priors,\n",
    "                 categorical=categorical)\n",
    "    \n",
    "    model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8eb911-f752-4c3e-8862-0e5fce3344d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_priors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b79a64-168b-421e-8be8-676a04c8d74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.30.1 (20150306.0020)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"3114pt\" height=\"363pt\"\n",
       " viewBox=\"0.00 0.00 3114.00 363.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 359)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"white\" points=\"-4,5 -4,-359 3111,-359 3111,5 -4,5\"/>\n",
       "<g id=\"clust1\" class=\"cluster\"><title>cluster152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2562,-131C2562,-131 2676,-131 2676,-131 2682,-131 2688,-137 2688,-143 2688,-143 2688,-335 2688,-335 2688,-341 2682,-347 2676,-347 2676,-347 2562,-347 2562,-347 2556,-347 2550,-341 2550,-335 2550,-335 2550,-143 2550,-143 2550,-137 2556,-131 2562,-131\"/>\n",
       "<text text-anchor=\"middle\" x=\"2669.5\" y=\"-138.8\" font-family=\"Times,serif\" font-size=\"14.00\">152</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\"><title>cluster971</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2846,-131C2846,-131 2960,-131 2960,-131 2966,-131 2972,-137 2972,-143 2972,-143 2972,-335 2972,-335 2972,-341 2966,-347 2960,-347 2960,-347 2846,-347 2846,-347 2840,-347 2834,-341 2834,-335 2834,-335 2834,-143 2834,-143 2834,-137 2840,-131 2846,-131\"/>\n",
       "<text text-anchor=\"middle\" x=\"2953.5\" y=\"-138.8\" font-family=\"Times,serif\" font-size=\"14.00\">971</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\"><title>cluster699,189</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1423,-8C1423,-8 1511,-8 1511,-8 1517,-8 1523,-14 1523,-20 1523,-20 1523,-111 1523,-111 1523,-117 1517,-123 1511,-123 1511,-123 1423,-123 1423,-123 1417,-123 1411,-117 1411,-111 1411,-111 1411,-20 1411,-20 1411,-14 1417,-8 1423,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1492.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">699,189</text>\n",
       "</g>\n",
       "<!-- power&amp;arousal&amp;region -->\n",
       "<g id=\"node1\" class=\"node\"><title>power&amp;arousal&amp;region</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"92\" cy=\"-189\" rx=\"92.4462\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:arousal:region</text>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- memory -->\n",
       "<g id=\"node24\" class=\"node\"><title>memory</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"1467\" cy=\"-77\" rx=\"48.125\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1467\" y=\"-88.3\" font-family=\"Times,serif\" font-size=\"14.00\">memory</text>\n",
       "<text text-anchor=\"middle\" x=\"1467\" y=\"-73.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1467\" y=\"-58.3\" font-family=\"Times,serif\" font-size=\"14.00\">Bernoulli</text>\n",
       "</g>\n",
       "<!-- power&amp;arousal&amp;region&#45;&gt;memory -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>power&amp;arousal&amp;region&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137.976,-156.297C154.844,-146.326 174.577,-136.493 194,-131 311.589,-97.7462 1174.7,-82.4108 1408.65,-78.8373\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1409.04,-82.3318 1418.98,-78.6808 1408.93,-75.3326 1409.04,-82.3318\"/>\n",
       "</g>\n",
       "<!-- power&amp;arousal&amp;hemi -->\n",
       "<g id=\"node2\" class=\"node\"><title>power&amp;arousal&amp;hemi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"291\" cy=\"-189\" rx=\"88.0829\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:arousal:hemi</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;arousal&amp;hemi&#45;&gt;memory -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>power&amp;arousal&amp;hemi&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M334.794,-156.223C350.767,-146.311 369.471,-136.533 388,-131 485.863,-101.778 1198.36,-83.9132 1408.7,-79.2349\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1408.99,-82.7292 1418.91,-79.0092 1408.84,-75.7309 1408.99,-82.7292\"/>\n",
       "</g>\n",
       "<!-- power&amp;region -->\n",
       "<g id=\"node3\" class=\"node\"><title>power&amp;region</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"460\" cy=\"-189\" rx=\"62.3993\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"460\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:region</text>\n",
       "<text text-anchor=\"middle\" x=\"460\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"460\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;region&#45;&gt;memory -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>power&amp;region&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M491.377,-156.306C503.135,-146.401 517.246,-136.606 532,-131 613.662,-99.9701 1217.21,-83.6862 1408.81,-79.2592\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1409.04,-82.7548 1418.96,-79.0268 1408.88,-75.7567 1409.04,-82.7548\"/>\n",
       "</g>\n",
       "<!-- region -->\n",
       "<g id=\"node4\" class=\"node\"><title>region</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"583\" cy=\"-189\" rx=\"41.5782\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"583\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">region</text>\n",
       "<text text-anchor=\"middle\" x=\"583\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"583\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- region&#45;&gt;memory -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>region&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M603.4,-156.17C611.384,-146.381 621.424,-136.693 633,-131 702.129,-97.0001 1230.63,-82.935 1408.67,-79.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1408.96,-82.6247 1418.88,-78.9147 1408.81,-75.6262 1408.96,-82.6247\"/>\n",
       "</g>\n",
       "<!-- hemi -->\n",
       "<g id=\"node5\" class=\"node\"><title>hemi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"684\" cy=\"-189\" rx=\"41.5782\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"684\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">hemi</text>\n",
       "<text text-anchor=\"middle\" x=\"684\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"684\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- hemi&#45;&gt;memory -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>hemi&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M704.428,-156.228C712.414,-146.443 722.449,-136.744 734,-131 793.773,-101.278 1245.69,-84.7311 1408.64,-79.6816\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1409.06,-83.1704 1418.95,-79.3656 1408.85,-76.1737 1409.06,-83.1704\"/>\n",
       "</g>\n",
       "<!-- power&amp;arousal -->\n",
       "<g id=\"node6\" class=\"node\"><title>power&amp;arousal</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"809\" cy=\"-189\" rx=\"65.1436\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"809\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:arousal</text>\n",
       "<text text-anchor=\"middle\" x=\"809\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"809\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;arousal&#45;&gt;memory -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>power&amp;arousal&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M841.995,-156.591C854.27,-146.711 868.906,-136.859 884,-131 978.668,-94.2527 1280.8,-82.5803 1408.8,-79.2275\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1408.9,-82.7261 1418.81,-78.973 1408.73,-75.7284 1408.9,-82.7261\"/>\n",
       "</g>\n",
       "<!-- Intercept -->\n",
       "<g id=\"node7\" class=\"node\"><title>Intercept</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"939\" cy=\"-189\" rx=\"45.4433\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"939\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">Intercept</text>\n",
       "<text text-anchor=\"middle\" x=\"939\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"939\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- Intercept&#45;&gt;memory -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>Intercept&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M962.174,-156.465C971.015,-146.7 981.909,-136.952 994,-131 1065.64,-95.7357 1298.69,-83.5097 1408.61,-79.6353\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1408.98,-83.1249 1418.86,-79.2859 1408.74,-76.1289 1408.98,-83.1249\"/>\n",
       "</g>\n",
       "<!-- power&amp;valence&amp;hemi -->\n",
       "<g id=\"node8\" class=\"node\"><title>power&amp;valence&amp;hemi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1093\" cy=\"-189\" rx=\"89.2052\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:valence:hemi</text>\n",
       "<text text-anchor=\"middle\" x=\"1093\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1093\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;valence&amp;hemi&#45;&gt;memory -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>power&amp;valence&amp;hemi&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1139.77,-156.82C1155.77,-147.319 1174.16,-137.643 1192,-131 1264.07,-104.17 1352.05,-90.2624 1408.77,-83.5505\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1409.46,-86.9955 1418.99,-82.3795 1408.66,-80.041 1409.46,-86.9955\"/>\n",
       "</g>\n",
       "<!-- power&amp;valence&amp;region -->\n",
       "<g id=\"node9\" class=\"node\"><title>power&amp;valence&amp;region</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1296\" cy=\"-189\" rx=\"94.1301\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1296\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:valence:region</text>\n",
       "<text text-anchor=\"middle\" x=\"1296\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1296\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;valence&amp;region&#45;&gt;memory -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>power&amp;valence&amp;region&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1344.54,-156.773C1368.82,-141.159 1398.01,-122.381 1421.8,-107.076\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1423.79,-109.96 1430.3,-101.606 1420,-104.073 1423.79,-109.96\"/>\n",
       "</g>\n",
       "<!-- power&amp;hemi -->\n",
       "<g id=\"node10\" class=\"node\"><title>power&amp;hemi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1467\" cy=\"-189\" rx=\"57.4743\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1467\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:hemi</text>\n",
       "<text text-anchor=\"middle\" x=\"1467\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1467\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;hemi&#45;&gt;memory -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>power&amp;hemi&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1467,-151.372C1467,-142.927 1467,-133.829 1467,-125.011\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1470.5,-124.843 1467,-114.844 1463.5,-124.844 1470.5,-124.843\"/>\n",
       "</g>\n",
       "<!-- arousal&amp;valence -->\n",
       "<g id=\"node11\" class=\"node\"><title>arousal&amp;valence</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1614\" cy=\"-189\" rx=\"71.127\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1614\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">arousal:valence</text>\n",
       "<text text-anchor=\"middle\" x=\"1614\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1614\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- arousal&amp;valence&#45;&gt;memory -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>arousal&amp;valence&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1573.83,-157.942C1553.81,-142.959 1529.6,-124.842 1509.29,-109.646\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1511.24,-106.736 1501.14,-103.547 1507.05,-112.341 1511.24,-106.736\"/>\n",
       "</g>\n",
       "<!-- 1|elec_sigma -->\n",
       "<g id=\"node12\" class=\"node\"><title>1|elec_sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3044\" cy=\"-301\" rx=\"62.3385\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"3044\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\">1|elec_sigma</text>\n",
       "<text text-anchor=\"middle\" x=\"3044\" y=\"-297.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"3044\" y=\"-282.3\" font-family=\"Times,serif\" font-size=\"14.00\">HalfNormal</text>\n",
       "</g>\n",
       "<!-- 1|elec -->\n",
       "<g id=\"node23\" class=\"node\"><title>1|elec</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2948.25,-215.5 2857.75,-215.5 2857.75,-162.5 2948.25,-162.5 2948.25,-215.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2903\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">1|elec</text>\n",
       "<text text-anchor=\"middle\" x=\"2903\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2903\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- 1|elec_sigma&#45;&gt;1|elec -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1|elec_sigma&#45;&gt;1|elec</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3006.58,-270.811C2987.22,-255.707 2963.56,-237.244 2943.74,-221.781\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2945.82,-218.968 2935.78,-215.577 2941.52,-224.487 2945.82,-218.968\"/>\n",
       "</g>\n",
       "<!-- arousal -->\n",
       "<g id=\"node13\" class=\"node\"><title>arousal</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1745\" cy=\"-189\" rx=\"41.5782\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1745\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">arousal</text>\n",
       "<text text-anchor=\"middle\" x=\"1745\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1745\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- arousal&#45;&gt;memory -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>arousal&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1723.24,-156.95C1715.09,-147.343 1705.08,-137.568 1694,-131 1641.95,-100.141 1573.26,-87.2491 1525.12,-81.8637\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.18,-78.3511 1514.87,-80.7953 1524.46,-85.3133 1525.18,-78.3511\"/>\n",
       "</g>\n",
       "<!-- valence -->\n",
       "<g id=\"node14\" class=\"node\"><title>valence</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1846\" cy=\"-189\" rx=\"41.5782\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1846\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">valence</text>\n",
       "<text text-anchor=\"middle\" x=\"1846\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1846\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- valence&#45;&gt;memory -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>valence&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1824.75,-156.801C1816.57,-147.062 1806.42,-137.245 1795,-131 1749.5,-106.112 1606.1,-90.0388 1524.78,-82.6759\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1524.97,-79.1789 1514.69,-81.7789 1524.34,-86.1514 1524.97,-79.1789\"/>\n",
       "</g>\n",
       "<!-- 1|subj_sigma -->\n",
       "<g id=\"node15\" class=\"node\"><title>1|subj_sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2761\" cy=\"-301\" rx=\"62.3993\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"2761\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\">1|subj_sigma</text>\n",
       "<text text-anchor=\"middle\" x=\"2761\" y=\"-297.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2761\" y=\"-282.3\" font-family=\"Times,serif\" font-size=\"14.00\">HalfNormal</text>\n",
       "</g>\n",
       "<!-- 1|subj -->\n",
       "<g id=\"node21\" class=\"node\"><title>1|subj</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2664.25,-215.5 2573.75,-215.5 2573.75,-162.5 2664.25,-162.5 2664.25,-215.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2619\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">1|subj</text>\n",
       "<text text-anchor=\"middle\" x=\"2619\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2619\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- 1|subj_sigma&#45;&gt;1|subj -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1|subj_sigma&#45;&gt;1|subj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2723.32,-270.811C2703.82,-255.707 2679.99,-237.244 2660.03,-221.781\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2662.07,-218.934 2652.02,-215.577 2657.78,-224.467 2662.07,-218.934\"/>\n",
       "</g>\n",
       "<!-- power -->\n",
       "<g id=\"node16\" class=\"node\"><title>power</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1947\" cy=\"-189\" rx=\"41.5782\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"1947\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power</text>\n",
       "<text text-anchor=\"middle\" x=\"1947\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1947\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&#45;&gt;memory -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>power&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1925.88,-156.556C1917.71,-146.798 1907.53,-137.031 1896,-131 1832.83,-97.9619 1627.17,-84.7713 1525.28,-80.165\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.31,-76.6627 1515.16,-79.7203 1525,-83.656 1525.31,-76.6627\"/>\n",
       "</g>\n",
       "<!-- power&amp;region&amp;hemi -->\n",
       "<g id=\"node17\" class=\"node\"><title>power&amp;region&amp;hemi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2092\" cy=\"-189\" rx=\"84.2802\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"2092\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:region:hemi</text>\n",
       "<text text-anchor=\"middle\" x=\"2092\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2092\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;region&amp;hemi&#45;&gt;memory -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>power&amp;region&amp;hemi&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2049.03,-156.74C2033.38,-146.872 2015.07,-136.991 1997,-131 1910.64,-102.378 1643.93,-86.4438 1525.13,-80.6024\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.28,-77.1059 1515.12,-80.1173 1524.94,-84.0977 1525.28,-77.1059\"/>\n",
       "</g>\n",
       "<!-- power&amp;arousal&amp;valence -->\n",
       "<g id=\"node18\" class=\"node\"><title>power&amp;arousal&amp;valence</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2292\" cy=\"-189\" rx=\"97.3709\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"2292\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:arousal:valence</text>\n",
       "<text text-anchor=\"middle\" x=\"2292\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2292\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;arousal&amp;valence&#45;&gt;memory -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>power&amp;arousal&amp;valence&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2243.22,-156.513C2225.55,-146.626 2205.02,-136.79 2185,-131 2061.59,-95.3017 1673.41,-82.7601 1525.25,-79.204\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.08,-75.6993 1515.01,-78.9633 1524.92,-82.6973 1525.08,-75.6993\"/>\n",
       "</g>\n",
       "<!-- power&amp;valence -->\n",
       "<g id=\"node19\" class=\"node\"><title>power&amp;valence</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2475\" cy=\"-189\" rx=\"67.2629\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"2475\" y=\"-200.3\" font-family=\"Times,serif\" font-size=\"14.00\">power:valence</text>\n",
       "<text text-anchor=\"middle\" x=\"2475\" y=\"-185.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2475\" y=\"-170.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- power&amp;valence&#45;&gt;memory -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>power&amp;valence&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2441.11,-156.299C2428.51,-146.394 2413.48,-136.601 2398,-131 2316.25,-101.431 1716.25,-84.1692 1525.23,-79.3789\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.19,-75.8769 1515.11,-79.1271 1525.02,-82.8748 1525.19,-75.8769\"/>\n",
       "</g>\n",
       "<!-- 1|subj_offset -->\n",
       "<g id=\"node20\" class=\"node\"><title>1|subj_offset</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2619\" cy=\"-301\" rx=\"60.2186\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"2619\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\">1|subj_offset</text>\n",
       "<text text-anchor=\"middle\" x=\"2619\" y=\"-297.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2619\" y=\"-282.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- 1|subj_offset&#45;&gt;1|subj -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>1|subj_offset&#45;&gt;1|subj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2619,-263.372C2619,-251.287 2619,-237.866 2619,-225.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2622.5,-225.701 2619,-215.701 2615.5,-225.701 2622.5,-225.701\"/>\n",
       "</g>\n",
       "<!-- 1|subj&#45;&gt;memory -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>1|subj&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2596.09,-162.242C2583.96,-150.471 2568.07,-137.684 2551,-131 2455.41,-93.5657 1736.9,-81.4565 1525.4,-78.6837\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.17,-75.1805 1515.13,-78.5511 1525.08,-82.18 1525.17,-75.1805\"/>\n",
       "</g>\n",
       "<!-- 1|elec_offset -->\n",
       "<g id=\"node22\" class=\"node\"><title>1|elec_offset</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2903\" cy=\"-301\" rx=\"60.2186\" ry=\"37.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"2903\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\">1|elec_offset</text>\n",
       "<text text-anchor=\"middle\" x=\"2903\" y=\"-297.3\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"2903\" y=\"-282.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- 1|elec_offset&#45;&gt;1|elec -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1|elec_offset&#45;&gt;1|elec</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2903,-263.372C2903,-251.287 2903,-237.866 2903,-225.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2906.5,-225.701 2903,-215.701 2899.5,-225.701 2906.5,-225.701\"/>\n",
       "</g>\n",
       "<!-- 1|elec&#45;&gt;memory -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>1|elec&#45;&gt;memory</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2857.53,-172.584C2815.21,-158.993 2750.12,-139.995 2692,-131 2462.89,-95.5423 1736.79,-82.0535 1525.32,-78.8188\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1525.11,-75.3153 1515.05,-78.6637 1525,-82.3145 1525.11,-75.3153\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2b178659bc10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "617be5aa-acc1-426d-9ac4-c114f6e0ea61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "      <th>region</th>\n",
       "      <th>memory</th>\n",
       "      <th>arousal</th>\n",
       "      <th>valence</th>\n",
       "      <th>band</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>hemi</th>\n",
       "      <th>subj</th>\n",
       "      <th>elec</th>\n",
       "      <th>CA</th>\n",
       "      <th>CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.767419</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.087</td>\n",
       "      <td>hfa</td>\n",
       "      <td>-26.76</td>\n",
       "      <td>left</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>R1001P_LDH1-LDH2</td>\n",
       "      <td>low</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1.166443</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.083</td>\n",
       "      <td>hfa</td>\n",
       "      <td>-26.76</td>\n",
       "      <td>left</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>R1001P_LDH1-LDH2</td>\n",
       "      <td>med</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1.398337</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.042</td>\n",
       "      <td>hfa</td>\n",
       "      <td>-26.76</td>\n",
       "      <td>left</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>R1001P_LDH1-LDH2</td>\n",
       "      <td>low</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.142283</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.333</td>\n",
       "      <td>hfa</td>\n",
       "      <td>-26.76</td>\n",
       "      <td>left</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>R1001P_LDH1-LDH2</td>\n",
       "      <td>med</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.701030</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.240</td>\n",
       "      <td>hfa</td>\n",
       "      <td>-26.76</td>\n",
       "      <td>left</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>R1001P_LDH1-LDH2</td>\n",
       "      <td>low</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475578</th>\n",
       "      <td>-0.473307</td>\n",
       "      <td>Amy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.052</td>\n",
       "      <td>hfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>R1409D</td>\n",
       "      <td>R1409D_LAD4-LAD5</td>\n",
       "      <td>low</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475579</th>\n",
       "      <td>-1.179263</td>\n",
       "      <td>Amy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.031</td>\n",
       "      <td>hfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>R1409D</td>\n",
       "      <td>R1409D_LAD4-LAD5</td>\n",
       "      <td>low</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475580</th>\n",
       "      <td>-0.055205</td>\n",
       "      <td>Amy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.250</td>\n",
       "      <td>hfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>R1409D</td>\n",
       "      <td>R1409D_LAD4-LAD5</td>\n",
       "      <td>low</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475582</th>\n",
       "      <td>-1.011568</td>\n",
       "      <td>Amy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>hfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>R1409D</td>\n",
       "      <td>R1409D_LAD4-LAD5</td>\n",
       "      <td>low</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475583</th>\n",
       "      <td>0.386525</td>\n",
       "      <td>Amy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.000</td>\n",
       "      <td>hfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>R1409D</td>\n",
       "      <td>R1409D_LAD4-LAD5</td>\n",
       "      <td>low</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699189 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            power region  memory  arousal  valence band  y_coord  hemi  \\\n",
       "600      0.767419   Hipp       0    0.135    0.087  hfa   -26.76  left   \n",
       "601      1.166443   Hipp       0    0.530    0.083  hfa   -26.76  left   \n",
       "602      1.398337   Hipp       0    0.322    0.042  hfa   -26.76  left   \n",
       "604      0.142283   Hipp       0    0.418    0.333  hfa   -26.76  left   \n",
       "605      0.701030   Hipp       0    0.133    0.240  hfa   -26.76  left   \n",
       "...           ...    ...     ...      ...      ...  ...      ...   ...   \n",
       "1475578 -0.473307    Amy       0    0.200    0.052  hfa      NaN  left   \n",
       "1475579 -1.179263    Amy       0    0.277    0.031  hfa      NaN  left   \n",
       "1475580 -0.055205    Amy       0    0.255    0.250  hfa      NaN  left   \n",
       "1475582 -1.011568    Amy       0    0.235   -0.010  hfa      NaN  left   \n",
       "1475583  0.386525    Amy       0    0.235    0.000  hfa      NaN  left   \n",
       "\n",
       "           subj              elec   CA       CV  \n",
       "600      R1001P  R1001P_LDH1-LDH2  low  neutral  \n",
       "601      R1001P  R1001P_LDH1-LDH2  med  neutral  \n",
       "602      R1001P  R1001P_LDH1-LDH2  low  neutral  \n",
       "604      R1001P  R1001P_LDH1-LDH2  med      pos  \n",
       "605      R1001P  R1001P_LDH1-LDH2  low      pos  \n",
       "...         ...               ...  ...      ...  \n",
       "1475578  R1409D  R1409D_LAD4-LAD5  low  neutral  \n",
       "1475579  R1409D  R1409D_LAD4-LAD5  low  neutral  \n",
       "1475580  R1409D  R1409D_LAD4-LAD5  low      pos  \n",
       "1475582  R1409D  R1409D_LAD4-LAD5  low  neutral  \n",
       "1475583  R1409D  R1409D_LAD4-LAD5  low  neutral  \n",
       "\n",
       "[699189 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec38c36-f9eb-4986-abfc-3c9231fcfeaf",
   "metadata": {},
   "source": [
    "Below are some utility functions in case you have run the model and are loading it using arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6582292-5aaf-4048-827e-07abf2d6408a",
   "metadata": {},
   "source": [
    "Once I am running models I can do model comparison using: \n",
    "\n",
    "https://arviz-devs.github.io/arviz/api/generated/arviz.compare.html\n",
    "and \n",
    "https://arviz-devs.github.io/arviz/api/generated/arviz.plot_compare.html\n",
    "\n",
    "as in: https://bambinos.github.io/bambi/main/notebooks/model_comparison.html?highlight=waic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c034824-571e-457a-a92c-644d0e55927a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, arousal:valence, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='985' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.07% [985/7000 14:35<1:29:07 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 1: Effect of arousal and continuous, linear valence on recall \n",
    "\n",
    "behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv', low_memory=False)\n",
    "behav_df = behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "behav_df = behav_df[behav_df.type=='WORD']\n",
    "# Center valence at 0 to capture polarity \n",
    "behav_df.valence = behav_df.valence - behav_df.valence.mean()\n",
    "behav_df = behav_df[['recalled', 'arousal', 'valence', 'subj']]\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'valence'] \n",
    "Intx = ['arousal:valence']\n",
    "rand_effect = ['subj']\n",
    "\n",
    "# Drop nan data\n",
    "behav_df = behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(behav_df, y, X, Intx, rand_effect, rand_slopes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f881a649-7557-4a84-82ab-b8951016fae0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, arousal:valence_squared, valence_squared, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7000' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7000/7000 43:16<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_500 tune and 2_000 draw iterations (3_000 + 4_000 draws total) took 2597 seconds.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fitted_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Drop nan data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m behav_df \u001b[38;5;241m=\u001b[39m behav_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39mX)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbehav_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIntx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_effect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_slopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(df, y, X, Intx, rand_effect, rand_slopes, priors, categorical, cores, chains, tune, draws, target_accept, model_fam, output_dir, return_model)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecalled\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# sample from posterior-predictive distribution to make in-sample predictions \u001b[39;00m\n\u001b[1;32m     75\u001b[0m     model\u001b[38;5;241m.\u001b[39mpredict(results, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m     y_posterior \u001b[38;5;241m=\u001b[39m \u001b[43mfitted_model\u001b[49m\u001b[38;5;241m.\u001b[39mposterior[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstack(samples\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdraw\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Select 25% of the values in the posterior, making sure we take values from both chains.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     y_posterior \u001b[38;5;241m=\u001b[39m recall_posterior[:, ::\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fitted_model' is not defined"
     ]
    }
   ],
   "source": [
    "# # Model 2: Effect of arousal and continuous, quadratic valence on recall\n",
    "\n",
    "# behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv', low_memory=False)\n",
    "# behav_df = behav_df.drop(columns=['Unnamed: 0'])\n",
    "# # Get only encoding events\n",
    "# behav_df = behav_df[behav_df.type=='WORD']\n",
    "# # Center valence at 0 to capture polarity \n",
    "# behav_df.valence = behav_df.valence - behav_df.valence.mean()\n",
    "# behav_df = behav_df[['recalled', 'arousal', 'valence', 'serialpos', 'subj']]\n",
    "\n",
    "# behav_df['valence_squared'] = behav_df['valence']**2\n",
    "\n",
    "# y = 'recalled'\n",
    "# X = ['arousal', 'valence_squared'] \n",
    "# Intx = ['arousal:valence_squared']\n",
    "# rand_effect = 'subj'\n",
    "\n",
    "# # Drop nan data\n",
    "# behav_df = behav_df.dropna(subset=X)\n",
    "\n",
    "# run_model(behav_df, y, X, Intx, rand_effect, rand_slopes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd824ff3-fdfc-466d-9dca-194ecda08b3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, arousal:CV, CV, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7000' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7000/7000 48:46<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_500 tune and 2_000 draw iterations (3_000 + 4_000 draws total) took 2926 seconds.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_969/771271935.py:104: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "              index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "            arousal &  0.510 & 0.109 &     0.297 &      0.718 \\\\ \\hline\n",
      "arousal:CV[neutral] & -0.324 & 0.124 &    -0.559 &     -0.079 \\\\ \\hline\n",
      "    arousal:CV[pos] & -0.040 & 0.146 &    -0.345 &      0.230 \\\\ \\hline\n",
      "        CV[neutral] &  0.042 & 0.067 &    -0.093 &      0.168 \\\\ \\hline\n",
      "            CV[pos] & -0.040 & 0.073 &    -0.179 &      0.103 \\\\ \\hline\n",
      "arousal:CV[neutral] & -0.324 & 0.124 &    -0.559 &     -0.079 \\\\ \\hline\n",
      "    arousal:CV[pos] & -0.040 & 0.146 &    -0.345 &      0.230 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Model 3: Effect of arousal and binned valence on recall\n",
    "\n",
    "# behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv', low_memory=False)\n",
    "# behav_df = behav_df.drop(columns=['Unnamed: 0'])\n",
    "# # Get only encoding events\n",
    "# behav_df = behav_df[behav_df.type=='WORD']\n",
    "# # Bin the arousal and valence \n",
    "# bins = np.linspace(0,1,4)\n",
    "# behav_df['CA'] = pd.cut(behav_df['arousal'], bins=bins,\n",
    "#                                                     labels=['low', 'med', 'high'])\n",
    "# behav_df['CV'] = pd.cut(behav_df['valence'], bins=bins,\n",
    "#                                                     labels=['neg', 'neutral', 'pos'])\n",
    "\n",
    "\n",
    "# cat_type = CategoricalDtype(categories=['neutral', 'pos', 'neg'], ordered=True)\n",
    "# behav_df.CV = behav_df.CV.astype(cat_type)\n",
    "\n",
    "# behav_df = behav_df[['recalled', 'CV', 'arousal', 'subj']]\n",
    "\n",
    "\n",
    "# y = 'recalled'\n",
    "# X = ['arousal', 'CV'] \n",
    "# # Intx = None\n",
    "# Intx = ['arousal:CV']\n",
    "# rand_effect = 'subj'\n",
    "\n",
    "# # Drop nan data\n",
    "# behav_df = behav_df.dropna(subset=X)\n",
    "\n",
    "# run_model(behav_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=['CV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa0eb5-6fe6-44a1-abca-8b984ab306ed",
   "metadata": {},
   "source": [
    "I am taking out this model comparison and saving it just for the depression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6bdd5a-7dc5-4cb5-b0d5-4446fdf8cb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>binned</th>\n",
       "      <td>0</td>\n",
       "      <td>-64497.384090</td>\n",
       "      <td>162.346960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.860004</td>\n",
       "      <td>157.100620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadratic</th>\n",
       "      <td>1</td>\n",
       "      <td>-64501.538420</td>\n",
       "      <td>159.893216</td>\n",
       "      <td>4.154330</td>\n",
       "      <td>0.114835</td>\n",
       "      <td>157.080034</td>\n",
       "      <td>3.393266</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>2</td>\n",
       "      <td>-64507.030791</td>\n",
       "      <td>160.413835</td>\n",
       "      <td>9.646701</td>\n",
       "      <td>0.025161</td>\n",
       "      <td>157.058995</td>\n",
       "      <td>4.791465</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rank           loo       p_loo     d_loo    weight          se  \\\n",
       "binned        0 -64497.384090  162.346960  0.000000  0.860004  157.100620   \n",
       "quadratic     1 -64501.538420  159.893216  4.154330  0.114835  157.080034   \n",
       "linear        2 -64507.030791  160.413835  9.646701  0.025161  157.058995   \n",
       "\n",
       "                dse  warning loo_scale  \n",
       "binned     0.000000    False       log  \n",
       "quadratic  3.393266    False       log  \n",
       "linear     4.791465    False       log  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Model comparison: use Bayes Factor to determine which model to use. \n",
    "\n",
    "# # Load each model\n",
    "# linear_valence = az.from_netcdf('/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/recalled_arousal_valence_model')\n",
    "# quadratic_valence = az.from_netcdf(f'/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/recalled_arousal_valence_squared_model')\n",
    "# binned_valence = az.from_netcdf(f'/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/recalled_arousal_CV_model')\n",
    "\n",
    "# models = {\"continuous (linear)\": linear_valence, \n",
    "#           \"continuous (quadratic)\": quadratic_valence,\n",
    "#           \"binned\": binned_valence}\n",
    "# df_compare = az.compare(models, ic='loo')\n",
    "# plot_df = df_compare.reset_index().rename(columns={'index':'model'})[['model', 'loo']]\n",
    "\n",
    "# c_string = '|c'*plot_df.shape[1] + '|'\n",
    "# print(plot_df.to_latex(index=False, \n",
    "#                                         column_format=c_string).replace(\"\\\\\\n\", \"\\\\ \\hline\\n\"))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9912f254-cc40-4592-bcea-29db150eee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_60460/3109756353.py:3: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, is_stim:arousal, is_stim:valence, arousal:valence, is_stim, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 03:42<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 500 tune and 1_000 draw iterations (2_000 + 4_000 draws total) took 223 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_60460/1434725164.py:99: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "             index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "           arousal &  0.641 & 0.224 &     0.210 &      1.088 \\\\ \\hline\n",
      "   arousal:valence & -0.298 & 0.920 &    -2.134 &      1.482 \\\\ \\hline\n",
      "is\\_stim:arousal[1] & -0.661 & 0.345 &    -1.347 &     -0.026 \\\\ \\hline\n",
      "           valence &  0.023 & 0.455 &    -0.861 &      0.904 \\\\ \\hline\n",
      "   arousal:valence & -0.298 & 0.920 &    -2.134 &      1.482 \\\\ \\hline\n",
      "is\\_stim:valence[1] &  0.262 & 0.366 &    -0.414 &      0.995 \\\\ \\hline\n",
      "        is\\_stim[1] &  0.073 & 0.134 &    -0.176 &      0.346 \\\\ \\hline\n",
      "is\\_stim:valence[1] &  0.262 & 0.366 &    -0.414 &      0.995 \\\\ \\hline\n",
      "is\\_stim:arousal[1] & -0.661 & 0.345 &    -1.347 &     -0.026 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Effect of stimulation to Hipp on recall as a function of arousal and valence: \n",
    "\n",
    "stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
    "stim_behav_df = stim_behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.type=='WORD']\n",
    "\n",
    "# Get only HIppAmy stim:\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.stim_area=='Hipp']\n",
    " \n",
    "# Set up squared valence \n",
    "stim_behav_df['valence'] = stim_behav_df['valence'] - stim_behav_df['valence'].mean()\n",
    "# stim_behav_df['valence_squared'] = stim_behav_df['valence']**2\n",
    "\n",
    "stim_behav_df = stim_behav_df[['recalled', 'valence', 'arousal', 'subj', 'is_stim']]\n",
    "\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'valence', 'is_stim'] \n",
    "# Intx = None\n",
    "Intx = ['arousal:valence',\n",
    "       'is_stim:valence', \n",
    "       'is_stim:arousal']\n",
    "\n",
    "rand_effect = ['subj']\n",
    "categorical=['is_stim']\n",
    "label = (f\"{y}\" + \"_{}\"*len(X)).format(*X) +'_HippOnly'\n",
    "\n",
    "# Drop nan data\n",
    "stim_behav_df = stim_behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(stim_behav_df, y, X, Intx, rand_effect, chains=4, cores=4, tune=500, draws=1000,\n",
    "          rand_slopes=False, categorical=categorical, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88dd60c7-2959-4f7e-ad4c-f3f4f37e4f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_60460/239969250.py:3: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, is_stim:arousal, is_stim:valence, arousal:valence, is_stim, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7000' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7000/7000 03:51<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_500 tune and 2_000 draw iterations (3_000 + 4_000 draws total) took 232 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_60460/1434725164.py:99: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "             index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "           arousal &  0.697 & 0.223 &     0.266 &      1.140 \\\\ \\hline\n",
      "   arousal:valence & -0.639 & 0.877 &    -2.396 &      1.007 \\\\ \\hline\n",
      "is\\_stim:arousal[1] & -0.686 & 0.344 &    -1.358 &     -0.016 \\\\ \\hline\n",
      "           valence &  0.399 & 0.437 &    -0.451 &      1.230 \\\\ \\hline\n",
      "   arousal:valence & -0.639 & 0.877 &    -2.396 &      1.007 \\\\ \\hline\n",
      "is\\_stim:valence[1] &  0.158 & 0.347 &    -0.554 &      0.809 \\\\ \\hline\n",
      "        is\\_stim[1] &  0.037 & 0.134 &    -0.213 &      0.304 \\\\ \\hline\n",
      "is\\_stim:valence[1] &  0.158 & 0.347 &    -0.554 &      0.809 \\\\ \\hline\n",
      "is\\_stim:arousal[1] & -0.686 & 0.344 &    -1.358 &     -0.016 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Effect of stimulation to HippAmy on recall as a function of arousal and valence: \n",
    "\n",
    "stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
    "stim_behav_df = stim_behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.type=='WORD']\n",
    "\n",
    "# Get only HIppAmy stim:\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.stim_group=='HippAmy']\n",
    " \n",
    "# Set up squared valence \n",
    "stim_behav_df['valence'] = stim_behav_df['valence'] - stim_behav_df['valence'].mean()\n",
    "# stim_behav_df['valence_squared'] = stim_behav_df['valence']**2\n",
    "\n",
    "stim_behav_df = stim_behav_df[['recalled', 'valence', 'arousal', 'subj', 'is_stim']]\n",
    "\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'valence', 'is_stim'] \n",
    "# Intx = None\n",
    "Intx = ['arousal:valence',\n",
    "       'is_stim:valence', \n",
    "       'is_stim:arousal']\n",
    "\n",
    "rand_effect = ['subj']\n",
    "categorical=['is_stim']\n",
    "\n",
    "# Drop nan data\n",
    "stim_behav_df = stim_behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(stim_behav_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a3b3140-4bf1-4362-ab5e-e268d51e9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_82215/2281045493.py:3: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, is_stim:arousal, is_stim:valence, arousal:valence, is_stim, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7000' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7000/7000 06:27<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_500 tune and 2_000 draw iterations (3_000 + 4_000 draws total) took 387 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_82215/3223192719.py:111: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "             index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "           arousal &  0.150 & 0.246 &    -0.340 &      0.624 \\\\ \\hline\n",
      "   arousal:valence &  0.208 & 0.970 &    -1.690 &      2.101 \\\\ \\hline\n",
      "is\\_stim:arousal[1] &  0.108 & 0.380 &    -0.623 &      0.847 \\\\ \\hline\n",
      "           valence & -0.212 & 0.469 &    -1.197 &      0.639 \\\\ \\hline\n",
      "   arousal:valence &  0.208 & 0.970 &    -1.690 &      2.101 \\\\ \\hline\n",
      "is\\_stim:valence[1] &  0.045 & 0.347 &    -0.653 &      0.698 \\\\ \\hline\n",
      "        is\\_stim[1] &  0.013 & 0.147 &    -0.273 &      0.293 \\\\ \\hline\n",
      "is\\_stim:valence[1] &  0.045 & 0.347 &    -0.653 &      0.698 \\\\ \\hline\n",
      "is\\_stim:arousal[1] &  0.108 & 0.380 &    -0.623 &      0.847 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2 control: Effect of stimulation to MTL on recall as a function of arousal and valence: \n",
    "\n",
    "stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
    "stim_behav_df = stim_behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.type=='WORD']\n",
    "\n",
    "# Get only HIppAmy stim:\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.stim_group=='MTL']\n",
    " \n",
    "# Set up squared valence \n",
    "stim_behav_df['valence'] = stim_behav_df['valence'] - stim_behav_df['valence'].mean()\n",
    "# stim_behav_df['valence_squared'] = stim_behav_df['valence']**2\n",
    "\n",
    "stim_behav_df = stim_behav_df[['recalled', 'valence', 'arousal', 'subj', 'is_stim']]\n",
    "\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'valence', 'is_stim'] \n",
    "# Intx = None\n",
    "Intx = ['arousal:valence',\n",
    "       'is_stim:valence', \n",
    "       'is_stim:arousal']\n",
    "\n",
    "rand_effect = ['subj']\n",
    "categorical=['is_stim']\n",
    "\n",
    "# Drop nan data\n",
    "stim_behav_df = stim_behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(stim_behav_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3053951-1a16-4a24-9239-d80358bac3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_82215/525700066.py:3: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, is_stim:serialpos, is_stim:arousal, is_stim:valence, arousal:valence, serialpos, is_stim, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='5388' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      76.97% [5388/7000 03:36<01:04 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 2 control 2: Effect of stimulation to HippAmy on recall as a function of arousal and valence and serial position: \n",
    "\n",
    "stim_behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/all_stim_ev.csv')\n",
    "stim_behav_df = stim_behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.type=='WORD']\n",
    "\n",
    "# Get only HIppAmy stim:\n",
    "stim_behav_df = stim_behav_df[stim_behav_df.stim_group=='HippAmy']\n",
    "\n",
    "\n",
    " \n",
    "# Set up squared valence \n",
    "stim_behav_df['valence'] = stim_behav_df['valence'] - stim_behav_df['valence'].mean()\n",
    "# stim_behav_df['valence_squared'] = stim_behav_df['valence']**2\n",
    "\n",
    "stim_behav_df = stim_behav_df[['recalled', 'valence', 'arousal', 'subj', 'is_stim', 'serialpos']]\n",
    "\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'valence', 'is_stim', 'serialpos'] \n",
    "# Intx = None\n",
    "Intx = ['arousal:valence',\n",
    "       'is_stim:valence', \n",
    "       'is_stim:arousal', \n",
    "       'is_stim:serialpos']\n",
    "\n",
    "rand_effect = ['subj']\n",
    "categorical=['is_stim']\n",
    "\n",
    "# Drop nan data\n",
    "stim_behav_df = stim_behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(stim_behav_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49e1f64b-41a1-4286-b316-866d52dcf697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_82215/2075340377.py:7: DtypeWarning: Columns (4,26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv')\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subject_offset, 1|subject_sigma, CBDI:arousal, CBDI:CV, arousal:CV, CBDI, CV, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7000' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7000/7000 14:05<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_500 tune and 2_000 draw iterations (3_000 + 4_000 draws total) took 846 seconds.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_82215/3223192719.py:111: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "                 index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "               arousal &  0.959 & 0.197 &     0.572 &      1.337 \\\\ \\hline\n",
      "   arousal:CV[neutral] & -0.483 & 0.217 &    -0.911 &     -0.059 \\\\ \\hline\n",
      "       arousal:CV[neg] & -0.708 & 0.279 &    -1.255 &     -0.164 \\\\ \\hline\n",
      "    CBDI:arousal[high] & -0.449 & 0.175 &    -0.811 &     -0.116 \\\\ \\hline\n",
      "           CV[neutral] &  0.159 & 0.087 &    -0.008 &      0.329 \\\\ \\hline\n",
      "               CV[neg] &  0.313 & 0.143 &     0.051 &      0.603 \\\\ \\hline\n",
      "   arousal:CV[neutral] & -0.483 & 0.217 &    -0.911 &     -0.059 \\\\ \\hline\n",
      "       arousal:CV[neg] & -0.708 & 0.279 &    -1.255 &     -0.164 \\\\ \\hline\n",
      "CBDI:CV[high, neutral] &  0.070 & 0.062 &    -0.053 &      0.190 \\\\ \\hline\n",
      "    CBDI:CV[high, neg] &  0.210 & 0.105 &     0.010 &      0.410 \\\\ \\hline\n",
      "            CBDI[high] & -0.326 & 0.206 &    -0.724 &      0.076 \\\\ \\hline\n",
      "CBDI:CV[high, neutral] &  0.070 & 0.062 &    -0.053 &      0.190 \\\\ \\hline\n",
      "    CBDI:CV[high, neg] &  0.210 & 0.105 &     0.010 &      0.410 \\\\ \\hline\n",
      "    CBDI:arousal[high] & -0.449 & 0.175 &    -0.811 &     -0.116 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Effect of depression on recall as a function of binned valence and cont. arousal: \n",
    "\n",
    "# First, load the Beck Scores: \n",
    "BeckScores = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/Beck_Scores.csv')\n",
    "BeckScores.rename(columns={'Subject Code':'subject'}, inplace=True)\n",
    "\n",
    "behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv')\n",
    "behav_df = behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "behav_df = behav_df[behav_df.type=='WORD']\n",
    "\n",
    "# add back in the Beck Scores \n",
    "behav_df = behav_df.merge(BeckScores, on='subject')\n",
    "\n",
    "# Using terciles:\n",
    "behav_df['CBDI'] = pd.qcut(behav_df['BDI'], q=3,\n",
    "                                                    labels=['low', 'med', 'high'])\n",
    "behav_df['CBAI'] = pd.qcut(behav_df['BAI'], q=3,\n",
    "                                                    labels=['low', 'med', 'high'])\n",
    "\n",
    "# Should I get rid of the neutral CBDI? Not in the original analysis.... \n",
    "behav_df = behav_df[behav_df['CBDI']!='med']\n",
    "\n",
    "# Bin the arousal and valence \n",
    "bins = np.linspace(0,1,4)\n",
    "behav_df['CA'] = pd.cut(behav_df['arousal'], bins=bins,\n",
    "                                                    labels=['low', 'med', 'high'])\n",
    "behav_df['CV'] = pd.cut(behav_df['valence'], bins=bins,\n",
    "                                                    labels=['neg', 'neutral', 'pos'])\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['low', 'high'], ordered=True)\n",
    "behav_df.CBDI = behav_df.CBDI.astype(cat_type)\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['pos', 'neutral', 'neg'], ordered=True)\n",
    "behav_df.CV = behav_df.CV.astype(cat_type)\n",
    "\n",
    "\n",
    "behav_df = behav_df[['recalled', 'CV', 'arousal', 'subject', 'CBDI']]\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'CV', 'CBDI'] \n",
    "Intx = ['arousal:CV',\n",
    "        'CBDI:CV',\n",
    "        'CBDI:arousal']\n",
    "rand_effect = ['subject']\n",
    "categorical = ['CBDI', 'CV']      \n",
    "\n",
    "# Drop nan data\n",
    "behav_df = behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(behav_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d539fb0-f728-44e3-82d7-32ed53c8e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_140521/1271992092.py:7: DtypeWarning: Columns (4,26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv')\n",
      "Modeling the probability that recalled==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subject_offset, 1|subject_sigma, CBDI:arousal:valence, CBDI:arousal, CBDI:valence, arousal:valence, CBDI, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7000' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7000/7000 14:16<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_500 tune and 2_000 draw iterations (3_000 + 4_000 draws total) took 856 seconds.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_140521/327036856.py:112: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "                     index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "                   arousal &  0.587 & 0.116 &     0.358 &      0.812 \\\\ \\hline\n",
      "           arousal:valence &  1.027 & 0.602 &    -0.169 &      2.186 \\\\ \\hline\n",
      "        CBDI:arousal[high] & -0.397 & 0.175 &    -0.740 &     -0.063 \\\\ \\hline\n",
      "CBDI:arousal:valence[high] & -0.276 & 0.912 &    -2.046 &      1.484 \\\\ \\hline\n",
      "                   valence & -0.605 & 0.285 &    -1.177 &     -0.071 \\\\ \\hline\n",
      "           arousal:valence &  1.027 & 0.602 &    -0.169 &      2.186 \\\\ \\hline\n",
      "        CBDI:valence[high] &  0.011 & 0.428 &    -0.831 &      0.832 \\\\ \\hline\n",
      "CBDI:arousal:valence[high] & -0.276 & 0.912 &    -2.046 &      1.484 \\\\ \\hline\n",
      "                CBDI[high] & -0.295 & 0.185 &    -0.656 &      0.064 \\\\ \\hline\n",
      "        CBDI:valence[high] &  0.011 & 0.428 &    -0.831 &      0.832 \\\\ \\hline\n",
      "        CBDI:arousal[high] & -0.397 & 0.175 &    -0.740 &     -0.063 \\\\ \\hline\n",
      "CBDI:arousal:valence[high] & -0.276 & 0.912 &    -2.046 &      1.484 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3 control: Effect of depression on recall as a function of cont. valence and cont. arousal: \n",
    "\n",
    "# First, load the Beck Scores: \n",
    "BeckScores = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/Beck_Scores.csv')\n",
    "BeckScores.rename(columns={'Subject Code':'subject'}, inplace=True)\n",
    "\n",
    "behav_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/events_all.csv')\n",
    "behav_df = behav_df.drop(columns=['Unnamed: 0'])\n",
    "# Get only encoding events\n",
    "behav_df = behav_df[behav_df.type=='WORD']\n",
    "\n",
    "# add back in the Beck Scores \n",
    "behav_df = behav_df.merge(BeckScores, on='subject')\n",
    "\n",
    "# Using terciles:\n",
    "behav_df['CBDI'] = pd.qcut(behav_df['BDI'], q=3,\n",
    "                                                    labels=['low', 'med', 'high'])\n",
    "behav_df['CBAI'] = pd.qcut(behav_df['BAI'], q=3,\n",
    "                                                    labels=['low', 'med', 'high'])\n",
    "\n",
    "# Should I get rid of the neutral CBDI? Not in the original analysis.... \n",
    "behav_df = behav_df[behav_df['CBDI']!='med']\n",
    "\n",
    "# make squared valence\n",
    "behav_df['valence'] = behav_df['valence'] - behav_df['valence'].mean()\n",
    "# behav_df['valence_squared'] = behav_df['valence']**2\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['low', 'high'], ordered=True)\n",
    "behav_df.CBDI = behav_df.CBDI.astype(cat_type)\n",
    "\n",
    "\n",
    "behav_df = behav_df[['recalled', 'valence', 'arousal', 'subject', 'CBDI']]\n",
    "\n",
    "y = 'recalled'\n",
    "X = ['arousal', 'valence', 'CBDI'] \n",
    "Intx = ['arousal:valence',\n",
    "        'CBDI:valence',\n",
    "        'CBDI:arousal',\n",
    "        'CBDI:arousal:valence']\n",
    "rand_effect = ['subject']\n",
    "categorical = ['CBDI']      \n",
    "\n",
    "# Drop nan data\n",
    "behav_df = behav_df.dropna(subset=X)\n",
    "\n",
    "run_model(behav_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de65ed6c-53f2-4bb3-953f-b339f8c795bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|}\n",
      "\\toprule\n",
      "              model &           loo \\\\ \\hline\n",
      "\\midrule\n",
      "             binned & -18200.103060 \\\\ \\hline\n",
      "continuous (linear) & -18200.789948 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_140521/3340815604.py:13: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(plot_df.to_latex(index=False,\n"
     ]
    }
   ],
   "source": [
    "# Model comparison: use PSI-LOO to determine which model to use for the depression data\n",
    "\n",
    "# Load each model\n",
    "linear_valence = az.from_netcdf('/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/recalled_arousal_valence_CBDI_model')\n",
    "binned_valence = az.from_netcdf(f'/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/recalled_arousal_CV_CBDI_model')\n",
    "\n",
    "models = {\"continuous (linear)\": linear_valence, \n",
    "          \"binned\": binned_valence}\n",
    "df_compare = az.compare(models, ic='loo')\n",
    "plot_df = df_compare.reset_index().rename(columns={'index':'model'})[['model', 'loo']]\n",
    "\n",
    "c_string = '|c'*plot_df.shape[1] + '|'\n",
    "print(plot_df.to_latex(index=False, \n",
    "                                        column_format=c_string).replace(\"\\\\\\n\", \"\\\\ \\hline\\n\"))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c6185a1-14e2-4e22-b08a-862d49db8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is word-level data. How do I recover electrode identity? \n",
    "pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED_elecInfo.csv')\n",
    "pow_df = pow_df.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cbc7096-3faf-4f6a-8d14-85a1a42feba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_df = pow_df[pow_df.region!='Frontal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b508dcb3-2a6a-46cc-b31f-09cb8a759851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/2765880.1.jupyter.q/ipykernel_9594/226823946.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pow_df['elec'] = pow_df['elec'].fillna(value='unlabeled')\n"
     ]
    }
   ],
   "source": [
    "pow_df['elec'] = pow_df['elec'].fillna(value='unlabeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94baae2-5ffb-4540-af5e-a4d589fdaedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n",
      "Modeling the probability that memory==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [1|elec_offset, 1|elec_sigma, 1|subj_offset, 1|subj_sigma, power:valence:region, power:arousal:region, power:arousal:valence, power:valence:hemi, power:arousal:hemi, power:region:hemi, power:region, power:hemi, power:valence, power:arousal, arousal:valence, hemi, power, region, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='132' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.65% [132/8000 13:40<13:35:21 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 4: Examine the effect of HFA power and word features on recall. \n",
    "\n",
    "# pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED.csv')\n",
    "pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_ELEC_RESOLVED.csv')\n",
    "pow_df = pow_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# rename the electrodes to properly do the elec random effects \n",
    "pow_df.elec = pow_df.apply(lambda x: f'{x.subj}_{x.elec}', axis=1)\n",
    "\n",
    "# # average across electrodes in a region(subj/region/hemi/ybin) but keep words (arousal/valence/memory) (for speed!)\n",
    "# pow_df = pow_df.groupby(['arousal','valence','subj','region','hemi', 'memory', 'band']).mean().reset_index()\n",
    "\n",
    "# De-mean the valence  \n",
    "pow_df['valence'] = pow_df['valence'] - pow_df['valence'].mean()\n",
    "\n",
    "# Set categorical orders \n",
    "\n",
    "cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "pow_df.hemi = pow_df.hemi.astype(cat_type)\n",
    "\n",
    "# Let's do separate models for band\n",
    "\n",
    "for band in ['hfa', 'theta']:\n",
    "        \n",
    "    pow_df = pow_df[pow_df.band==band]\n",
    "\n",
    "    y = 'memory'\n",
    "    X = ['arousal', 'valence', 'region', 'power', 'hemi'] \n",
    "    Intx = ['arousal:valence',\n",
    "            'power:arousal', \n",
    "            'power:valence',\n",
    "            'power:hemi',\n",
    "            'power:region',\n",
    "            'power:region:hemi',\n",
    "            'power:arousal:hemi',\n",
    "            'power:valence:hemi',\n",
    "            'power:arousal:valence',\n",
    "            'power:arousal:region', \n",
    "            'power:valence:region']\n",
    "\n",
    "    label = (f\"{y}\" + \"_{}\"*len(X)).format(*X) + f'_{band}' + 'elec_rand_effect'\n",
    "\n",
    "#             'power:hemi:region:arousal',\n",
    "#             'power:hemi:region:CV'\n",
    "    rand_effect = ['subj', 'elec']\n",
    "    categorical = ['hemi', 'region']\n",
    "\n",
    "    # Drop nan data\n",
    "    pow_df = pow_df.dropna(subset=X)\n",
    "\n",
    "    run_model(pow_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical,\n",
    "             chains=4, cores=4, tune=500, draws=1500, label=label, save_model_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69970221-e214-4ccd-94ae-ea8187d41f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "543f4ff4-5a1e-44ef-a6ed-d75f8301ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 4: Examine the effect of HFA power and word features on recall (binned CV). \n",
    "\n",
    "# pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED.csv')\n",
    "# pow_df = pow_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# # Set categorical orders \n",
    "\n",
    "# cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "# pow_df.hemi = pow_df.hemi.astype(cat_type)\n",
    "\n",
    "# cat_type = CategoricalDtype(categories=['neutral', 'pos', 'neg'], ordered=True)\n",
    "# pow_df.CV = pow_df.CV.astype(cat_type)\n",
    "\n",
    "# # Let's do separate models for band\n",
    "\n",
    "# for band in ['theta', 'gamma']:\n",
    "        \n",
    "#     pow_df = pow_df[pow_df.band==band]\n",
    "\n",
    "#     # Bin the arousal and valence \n",
    "#     bins = np.linspace(0,1,4)\n",
    "#     pow_df['CA'] = pd.cut(pow_df['arousal'], bins=bins,\n",
    "#                                                         labels=['low', 'med', 'high'])\n",
    "#     pow_df['CV'] = pd.cut(pow_df['valence'], bins=bins,\n",
    "#                                                         labels=['neg', 'neutral', 'pos'])\n",
    "\n",
    "\n",
    "#     y = 'memory'\n",
    "#     X = ['arousal', 'CV', 'region', 'power', 'hemi'] \n",
    "#     Intx = ['arousal:CV',\n",
    "#             'power:arousal', \n",
    "#             'power:CV',\n",
    "#             'power:hemi',\n",
    "#             'power:region',\n",
    "#             'power:hemi:region',\n",
    "#             'power:hemi:arousal',\n",
    "#             'power:hemi:CV',\n",
    "#             'power:arousal:CV',\n",
    "#             'power:arousal:region', \n",
    "#             'power:CV:region']\n",
    "\n",
    "#     label = (f\"{y}\" + \"_{}\"*len(X)).format(*X) + f'_{band}'\n",
    "\n",
    "# #             'power:hemi:region:arousal',\n",
    "# #             'power:hemi:region:CV'\n",
    "\n",
    "#     rand_effect = 'subj'\n",
    "#     categorical = ['hemi', 'region', 'CV']\n",
    "\n",
    "#     # Drop nan data\n",
    "#     pow_df = pow_df.dropna(subset=X)\n",
    "\n",
    "#     run_model(pow_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical,\n",
    "#              chains=4, cores=4, tune=500, draws=1000, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1278663-eac8-49a1-92e2-1ece71b2c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 4 control: Examine the effect of theta power and word features on recall. \n",
    "# # Note: this will override HFA results if you don't manually rename it. \n",
    "\n",
    "# pow_df = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED.csv')\n",
    "# pow_df = pow_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# # Set categorical orders \n",
    "\n",
    "# cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "# pow_df.hemi = pow_df.hemi.astype(cat_type)\n",
    "\n",
    "# cat_type = CategoricalDtype(categories=['neutral', 'pos', 'neg'], ordered=True)\n",
    "# pow_df.CV = pow_df.CV.astype(cat_type)\n",
    "\n",
    "\n",
    "# for band in ['theta']:\n",
    "#     pow_df = pow_df[pow_df.band==band]\n",
    "    \n",
    "#     # average across electrodes in a region (for speed!)\n",
    "# #     pow_df = pow_df.groupby(['arousal','valence','subj','region','hemi','memory']).mean().reset_index()\n",
    "\n",
    "#     # Bin the arousal and valence \n",
    "#     bins = np.linspace(0,1,4)\n",
    "#     pow_df['CA'] = pd.cut(pow_df['arousal'], bins=bins,\n",
    "#                                                         labels=['low', 'med', 'high'])\n",
    "#     pow_df['CV'] = pd.cut(pow_df['valence'], bins=bins,\n",
    "#                                                         labels=['neg', 'neutral', 'pos'])\n",
    "\n",
    "\n",
    "#     y = 'memory'\n",
    "#     X = ['arousal', 'CV', 'region', 'power', 'hemi'] \n",
    "#     Intx = ['arousal:CV',\n",
    "#             'power:arousal', \n",
    "#             'power:CV',\n",
    "#             'power:hemi',\n",
    "#             'power:region',\n",
    "#             'power:hemi:region',\n",
    "#             'power:hemi:arousal',\n",
    "#             'power:hemi:CV',\n",
    "#             'power:arousal:CV',\n",
    "#             'power:arousal:region', \n",
    "#             'power:CV:region']\n",
    "    \n",
    "# #             'power:hemi:region:arousal',\n",
    "# #             'power:hemi:region:CV'\n",
    "\n",
    "#     rand_effect = 'subj'\n",
    "#     categorical = ['hemi', 'region', 'CV']\n",
    "\n",
    "#     # Drop nan data\n",
    "#     pow_df = pow_df.dropna(subset=X)\n",
    "\n",
    "#     run_model(pow_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical,\n",
    "#              chains=4, cores=4, tune=500, draws=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c8f45-1e82-4a53-bb46-8129bb45cd28",
   "metadata": {},
   "source": [
    "Run tonight 4/14:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a601410-c36a-45be-ac18-0f5ac6875537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n",
      "Modeling the probability that memory==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, power:hemi:longitudinal_bin:valence, power:hemi:longitudinal_bin:arousal, power:valence:longitudinal_bin, power:arousal:longitudinal_bin, power:arousal:valence, power:hemi:longitudinal_bin, power:longitudinal_bin, power:hemi, power:valence, power:arousal, arousal:valence, hemi, power, longitudinal_bin, valence, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='226' class='' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.23% [226/7000 04:47<2:23:30 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 4 control 2: Examine the effect of HFA power and word features on recall, plus hipp AP position  \n",
    "\n",
    "pow_df_with_AP = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED_withAPaxis.csv')\n",
    "pow_df_with_AP = pow_df_with_AP.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Restrict this to gamma \n",
    "pow_df_with_AP = pow_df_with_AP[pow_df_with_AP.band=='gamma']\n",
    "\n",
    "# Restrict this to hippocampus\n",
    "pow_df_with_AP = pow_df_with_AP[pow_df_with_AP.region=='Hipp']\n",
    "\n",
    "# Bin longitudinal position\n",
    "APbins = [-50, -20, 10]\n",
    "pow_df_with_AP['longitudinal_bin' ] = np.nan\n",
    "pow_df_with_AP['longitudinal_bin'] = pd.cut(pow_df_with_AP['y_coord'], \n",
    "                                            bins=APbins, \n",
    "                                            labels=['posterior', 'anterior'])\n",
    "\n",
    "\n",
    "pow_df_with_AP = pow_df_with_AP.dropna(subset=['arousal', 'valence', 'region', 'power', 'hemi', 'longitudinal_bin'])\n",
    "pow_df_with_AP['longitudinal_bin'] = pow_df_with_AP.longitudinal_bin.astype(str)\n",
    "\n",
    "# average across electrodes in a region(subj/region/hemi/ybin) but keep words (arousal/valence/memory) (for speed!)\n",
    "pow_df_with_AP = pow_df_with_AP.groupby(['arousal','valence','subj','region','hemi', 'longitudinal_bin', 'memory']).mean().reset_index()\n",
    "\n",
    "# Bin the arousal and valence \n",
    "pow_df_with_AP['valence'] = pow_df_with_AP['valence'] - pow_df_with_AP['valence'].mean()\n",
    "\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "pow_df_with_AP.hemi = pow_df_with_AP.hemi.astype(cat_type)\n",
    "\n",
    "\n",
    "y = 'memory'\n",
    "X = ['arousal', 'valence', 'longitudinal_bin', 'power', 'hemi'] \n",
    "Intx = ['arousal:valence',\n",
    "        'power:arousal', \n",
    "        'power:valence',\n",
    "        'power:hemi',\n",
    "        'power:longitudinal_bin',\n",
    "        'power:hemi:longitudinal_bin',\n",
    "        'power:arousal:valence',\n",
    "        'power:arousal:longitudinal_bin', \n",
    "        'power:valence:longitudinal_bin', \n",
    "        'power:hemi:longitudinal_bin:arousal',\n",
    "        'power:hemi:longitudinal_bin:valence']\n",
    "\n",
    "rand_effect = 'subj'\n",
    "categorical = ['hemi', 'longitudinal_bin']\n",
    "\n",
    "# Drop nan data\n",
    "pow_df_with_AP = pow_df_with_AP.dropna(subset=X)\n",
    "\n",
    "run_model(pow_df_with_AP, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54b201a3-5699-440e-aef7-2e4b66d07522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hipp    62\n",
       "MTL     58\n",
       "Amy     36\n",
       "Name: rec_reg, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_t_test_hfa= pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/FR2_stim_allbands_diff_newfilt_600ms_50buff_hfa.csv')\n",
    "stim_t_test_data[stim_t_test_data.].rec_reg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5136541c-868d-4890-8ccf-46cb9a758aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>alpha_diff</th>\n",
       "      <th>beta_diff</th>\n",
       "      <th>hfa_diff</th>\n",
       "      <th>hgamma_diff</th>\n",
       "      <th>lgamma_diff</th>\n",
       "      <th>rec_hemi</th>\n",
       "      <th>rec_reg</th>\n",
       "      <th>stim</th>\n",
       "      <th>stim_avgy</th>\n",
       "      <th>stim_elec</th>\n",
       "      <th>stim_hemi</th>\n",
       "      <th>stim_reg</th>\n",
       "      <th>sub</th>\n",
       "      <th>theta_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>0.076897</td>\n",
       "      <td>0.041137</td>\n",
       "      <td>0.050789</td>\n",
       "      <td>0.018063</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.805</td>\n",
       "      <td>('LDA3', 'LDA4')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>-0.007687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012834</td>\n",
       "      <td>0.038192</td>\n",
       "      <td>-0.035213</td>\n",
       "      <td>-0.053542</td>\n",
       "      <td>-0.016884</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-16.805</td>\n",
       "      <td>('LDA3', 'LDA4')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>-0.014975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.025056</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>right</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.805</td>\n",
       "      <td>('LDA3', 'LDA4')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>0.004283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.028998</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>-0.011624</td>\n",
       "      <td>-0.018923</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>right</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-16.805</td>\n",
       "      <td>('LDA3', 'LDA4')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>-0.005781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.068119</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.013126</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>left</td>\n",
       "      <td>MTL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.805</td>\n",
       "      <td>('LDA3', 'LDA4')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1001P</td>\n",
       "      <td>-0.016093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>-0.008185</td>\n",
       "      <td>0.027435</td>\n",
       "      <td>-0.024094</td>\n",
       "      <td>-0.029180</td>\n",
       "      <td>-0.019008</td>\n",
       "      <td>right</td>\n",
       "      <td>Amy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.910</td>\n",
       "      <td>('HH1', 'HH2')</td>\n",
       "      <td>right</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1157C</td>\n",
       "      <td>-0.012724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>-0.027834</td>\n",
       "      <td>-0.007196</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>0.012301</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>right</td>\n",
       "      <td>MTL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.910</td>\n",
       "      <td>('HH1', 'HH2')</td>\n",
       "      <td>right</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1157C</td>\n",
       "      <td>-0.003106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>-0.069090</td>\n",
       "      <td>-0.037706</td>\n",
       "      <td>-0.006397</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>-0.028154</td>\n",
       "      <td>right</td>\n",
       "      <td>MTL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.910</td>\n",
       "      <td>('HH1', 'HH2')</td>\n",
       "      <td>right</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1157C</td>\n",
       "      <td>0.016279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.140038</td>\n",
       "      <td>0.025019</td>\n",
       "      <td>0.054474</td>\n",
       "      <td>-0.004436</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.555</td>\n",
       "      <td>('LHC1', 'LHC2')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1192C</td>\n",
       "      <td>-0.020870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.555</td>\n",
       "      <td>('LHC1', 'LHC2')</td>\n",
       "      <td>left</td>\n",
       "      <td>Hipp</td>\n",
       "      <td>R1192C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  alpha_diff  beta_diff  hfa_diff  hgamma_diff  lgamma_diff  \\\n",
       "0             0   -0.000895   0.076897  0.041137     0.050789     0.018063   \n",
       "1             1    0.012834   0.038192 -0.035213    -0.053542    -0.016884   \n",
       "2             2    0.025056   0.017386  0.001861     0.003706    -0.011146   \n",
       "3             3   -0.028998  -0.010492 -0.011624    -0.018923    -0.004325   \n",
       "4             4    0.012857   0.068119 -0.002471    -0.013126     0.015694   \n",
       "..          ...         ...        ...       ...          ...          ...   \n",
       "151         151   -0.008185   0.027435 -0.024094    -0.029180    -0.019008   \n",
       "152         152   -0.027834  -0.007196  0.019066     0.012301     0.012138   \n",
       "153         153   -0.069090  -0.037706 -0.006397     0.015361    -0.028154   \n",
       "154         154    0.017144   0.140038  0.025019     0.054474    -0.004436   \n",
       "155         155         NaN        NaN       NaN          NaN          NaN   \n",
       "\n",
       "    rec_hemi rec_reg  stim  stim_avgy         stim_elec stim_hemi stim_reg  \\\n",
       "0       left    Hipp   0.0    -16.805  ('LDA3', 'LDA4')      left     Hipp   \n",
       "1       left    Hipp   1.0    -16.805  ('LDA3', 'LDA4')      left     Hipp   \n",
       "2      right    Hipp   0.0    -16.805  ('LDA3', 'LDA4')      left     Hipp   \n",
       "3      right    Hipp   1.0    -16.805  ('LDA3', 'LDA4')      left     Hipp   \n",
       "4       left     MTL   0.0    -16.805  ('LDA3', 'LDA4')      left     Hipp   \n",
       "..       ...     ...   ...        ...               ...       ...      ...   \n",
       "151    right     Amy   1.0    -22.910    ('HH1', 'HH2')     right     Hipp   \n",
       "152    right     MTL   0.0    -22.910    ('HH1', 'HH2')     right     Hipp   \n",
       "153    right     MTL   1.0    -22.910    ('HH1', 'HH2')     right     Hipp   \n",
       "154     left    Hipp   0.0    -25.555  ('LHC1', 'LHC2')      left     Hipp   \n",
       "155     left    Hipp   1.0    -25.555  ('LHC1', 'LHC2')      left     Hipp   \n",
       "\n",
       "        sub  theta_diff  \n",
       "0    R1001P   -0.007687  \n",
       "1    R1001P   -0.014975  \n",
       "2    R1001P    0.004283  \n",
       "3    R1001P   -0.005781  \n",
       "4    R1001P   -0.016093  \n",
       "..      ...         ...  \n",
       "151  R1157C   -0.012724  \n",
       "152  R1157C   -0.003106  \n",
       "153  R1157C    0.016279  \n",
       "154  R1192C   -0.020870  \n",
       "155  R1192C         NaN  \n",
       "\n",
       "[156 rows x 15 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_t_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423c9b5-98e3-4175-9ceb-d39c2a356d17",
   "metadata": {},
   "source": [
    "Below you will find our one and only Bayesian linear mixed-effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4f73259-5077-48d9-9c38-e8064d98aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [hfa_diff_sigma, 1|sub_offset, 1|sub_sigma, stim:stim_hemi, stim_hemi, stim, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 00:41<00:00 Sampling 4 chains, 62 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_500 draw iterations (4_000 + 6_000 draws total) took 41 seconds.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 16 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 30 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_60460/1434725164.py:99: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|}\n",
      "\\toprule\n",
      "                    index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "                stim[1.0] & -0.030 & 0.037 &    -0.110 &      0.041 \\\\ \\hline\n",
      "          stim\\_hemi[left] &  0.008 & 0.097 &    -0.185 &      0.228 \\\\ \\hline\n",
      "stim:stim\\_hemi[1.0, left] & -0.006 & 0.041 &    -0.090 &      0.074 \\\\ \\hline\n",
      "          stim\\_hemi[left] &  0.008 & 0.097 &    -0.185 &      0.228 \\\\ \\hline\n",
      "stim:stim\\_hemi[1.0, left] & -0.006 & 0.041 &    -0.090 &      0.074 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 5: effect of stimulation on post-pre HFA and also every other power band. \n",
    "\n",
    "# run separate models for stimulation \n",
    "\n",
    "stim_t_test_data = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/FR2_stim_allbands_diff_newfilt_600ms_50buff_hfa.csv')\n",
    "stim_t_test_data = stim_t_test_data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# replace the non-stim data with the word 2 stim data only\n",
    "non_stim_path = '/home1/salman.qasim/Salman_Project/FR_Emotion/FR2_nostim_allbands_diff_newfilt_600ms_50buff_stimOFf_only.csv'\n",
    "\n",
    "# Set categorical orders \n",
    "\n",
    "cat_type = CategoricalDtype(categories=['MTL', 'Amy', 'Hipp'], ordered=True)\n",
    "stim_t_test_data.stim_reg = stim_t_test_data.stim_reg.astype(cat_type)\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['MTL', 'Amy', 'Hipp'], ordered=True)\n",
    "stim_t_test_data.rec_reg = stim_t_test_data.rec_reg.astype(cat_type)\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['MTL', 'Amy', 'Hipp'], ordered=True)\n",
    "stim_t_test_data.rec_reg = stim_t_test_data.rec_reg.astype(cat_type)\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "stim_t_test_data.stim_hemi = stim_t_test_data.stim_hemi.astype(cat_type)\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['right', 'left'], ordered=True)\n",
    "stim_t_test_data.rec_hemi = stim_t_test_data.rec_hemi.astype(cat_type)\n",
    "\n",
    "\n",
    "\n",
    "for sr in ['Amy']:\n",
    "    for rr in ['Amy']:\n",
    "        for y in ['hfa_diff']:\n",
    "            model_df = stim_t_test_data[(stim_t_test_data.stim_reg==sr)]\n",
    "            model_df = model_df[(model_df.rec_reg==rr)]\n",
    "\n",
    "            X = ['stim', 'stim_hemi'] \n",
    "            Intx = ['stim',\n",
    "                    'stim:stim_hemi']\n",
    "\n",
    "            label = (f\"{y}\" + \"_{}\"*len(X)).format(*X)+f'stim_{sr}_rec{rr}'\n",
    "\n",
    "            # y = 'beta_diff'\n",
    "            # X = ['stim', 'stim_reg', 'rec_reg', 'stim_hemi', 'rec_hemi'] \n",
    "            # Intx = ['stim:stim_reg',\n",
    "            #         'stim:stim_hemi', \n",
    "            #         'stim:stim_reg:rec_reg',\n",
    "            #         'stim:stim_hemi:rec_hemi']\n",
    "\n",
    "            rand_effect = 'sub'\n",
    "            categorical = X\n",
    "\n",
    "            # Drop nan data\n",
    "            model_df = model_df.dropna()\n",
    "\n",
    "            model, results = run_model(model_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical,\n",
    "                     chains=4, cores=4, tune=1000, draws=1500, target_accept=0.95, model_fam='gaussian', return_model=True, label = label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62a71602-47cd-4799-abcf-6adcdd6b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load all the stim models to see what best explains recall performance: \n",
    "# X = ['stim', 'stim_hemi'] \n",
    "# Intx = ['stim',\n",
    "#         'stim:stim_hemi']\n",
    "# # Load each model\n",
    "# models = {}\n",
    "# for sr in ['Hipp']:\n",
    "#     for rr in ['Hipp']:\n",
    "#         for y in ['theta_diff', 'alpha_diff', 'beta_diff', 'hfa_diff']:\n",
    "#             label = (f\"{y}\" + \"_{}\"*len(X)).format(*X)+f'stim_{sr}_rec{rr}_model'\n",
    "#             models[f'{y}_stim_{sr}_rec{rr}'] =  az.from_netcdf(f'/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/{label}')\n",
    "        \n",
    "# df_compare = az.compare(models, ic='loo')\n",
    "# plot_df = df_compare.reset_index().rename(columns={'index':'model'})[['model', 'loo']]\n",
    "\n",
    "# c_string = '|c'*plot_df.shape[1] + '|'\n",
    "# print(plot_df.to_latex(index=False, \n",
    "#                                         column_format=c_string).replace(\"\\\\\\n\", \"\\\\ \\hline\\n\"))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385bfcb-9c5e-4d8e-8da4-3c646f0994ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some data wrangling for easy plotting:\n",
    "\n",
    "# # rename cols\n",
    "# stim_t_test_data.rename(columns={'theta_diff': 'theta',\n",
    "#                                 'alpha_diff': 'alpha',\n",
    "#                                 'beta_diff': 'beta', \n",
    "#                                 'lgamma_diff': 'lgamma', \n",
    "#                                 'hgamma_diff': 'hgamma',\n",
    "#                                 'hfa_diff': 'hfa'}, inplace=True)\n",
    "# # melt df\n",
    "# stim_t_test_data = pd.melt(stim_t_test_data,\n",
    "#         id_vars=['sub', 'stim', 'stim_hemi', 'stim_reg', 'rec_reg', 'rec_hemi'], \n",
    "#         value_vars=['theta', 'alpha', 'beta', 'lgamma', 'hgamma', 'hfa']).rename(columns={'variable':'band'})\n",
    "# # plot\n",
    "# sns.catplot(data=stim_t_test_data, row_order=['Hipp', 'MTL', 'Amy'],\n",
    "#             x='band', \n",
    "#             y='value', \n",
    "#             hue='stim',\n",
    "#             col='rec_reg',\n",
    "#             row='stim_reg', \n",
    "#             kind = 'point', \n",
    "#             ci=68)\n",
    "\n",
    "# sns.catplot(data=stim_t_test_data, row_order=['Hipp', 'MTL', 'Amy'],\n",
    "#             x='band', \n",
    "#             y='value', \n",
    "#             hue='stim',\n",
    "#             col='rec_reg',\n",
    "#             row='stim_reg', \n",
    "#             kind = 'point', \n",
    "#             ci=68)\n",
    "# plt.savefig('/home1/salman.qasim/Salman_Project/FR_Emotion/Plots/effect_of_stim_allfreqs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16804898-0fc4-4e97-bee6-2a9d5b239498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting posterior predictive \n",
    "\n",
    "# model.predict(results, kind=\"pps\")\n",
    "# az.plot_ppc(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fce3cc0e-4710-4a93-8554-5fb185a2f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for saving and loading models\n",
    "\n",
    "# az.to_netcdf(results, '/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/test_save')\n",
    "# az.from_netcdf('/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels/test_save')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e39343-716a-4505-b16a-e8510952e8b7",
   "metadata": {},
   "source": [
    "Run tonight (4/14): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8813f-9a7f-4458-bfc2-d9b84adaa0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n",
      "Modeling the probability that memory==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, power:CV, power:arousal, power, CV, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 22:29<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 500 tune and 1_000 draw iterations (2_000 + 4_000 draws total) took 1350 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "/tmp/2765880.1.jupyter.q/ipykernel_25609/4159414056.py:95: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.reset_index().to_latex(index=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "            index &   mean &    sd &  hdi\\_2.5\\% &  hdi\\_97.5\\% \\\\ \\hline\n",
      "\\midrule\n",
      "          arousal &  0.551 & 0.075 &     0.407 &      0.704 \\\\ \\hline\n",
      "    power:arousal &  0.134 & 0.096 &    -0.045 &      0.329 \\\\ \\hline\n",
      "      CV[neutral] & -0.012 & 0.027 &    -0.065 &      0.040 \\\\ \\hline\n",
      "          CV[neg] & -0.078 & 0.048 &    -0.174 &      0.010 \\\\ \\hline\n",
      "power:CV[neutral] &  0.013 & 0.034 &    -0.055 &      0.079 \\\\ \\hline\n",
      "    power:CV[neg] &  0.009 & 0.061 &    -0.108 &      0.133 \\\\ \\hline\n",
      "            power & -0.059 & 0.046 &    -0.146 &      0.032 \\\\ \\hline\n",
      "    power:arousal &  0.134 & 0.096 &    -0.045 &      0.329 \\\\ \\hline\n",
      "power:CV[neutral] &  0.013 & 0.034 &    -0.055 &      0.079 \\\\ \\hline\n",
      "    power:CV[neg] &  0.009 & 0.061 &    -0.108 &      0.133 \\\\ \\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/salman.qasim/miniconda3/envs/bambi_env/lib/python3.10/site-packages/bambi/models.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[obj_cols] = data[obj_cols].apply(lambda x: x.astype(\"category\"))\n",
      "Modeling the probability that memory==1\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [1|subj_offset, 1|subj_sigma, power:CV, power:arousal, power, CV, arousal, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4577' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      76.28% [4577/6000 20:28<06:21 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 6: Effect of depression and power and arousal on memory and binned valence\n",
    "\n",
    "BeckScores = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/Beck_Scores.csv')\n",
    "BeckScores.rename(columns={'Subject Code':'subj'}, inplace=True)\n",
    "BeckScores = BeckScores.drop(columns=['Unnamed: 0'])\n",
    "pow_df_depr = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED.csv')\n",
    "pow_df_depr = pow_df_depr.drop(columns=['Unnamed: 0'])\n",
    "pow_df_depr = pow_df_depr.merge(BeckScores, on='subj')\n",
    "\n",
    "# Bin the BDI scores (this is ok because of clinical classification). \n",
    "pow_df_depr['CBDI'] = pd.qcut(pow_df_depr['BDI'], q=3,\n",
    "                                                    labels=['low', 'med', 'high'])\n",
    "\n",
    "# Should I get rid of the neutral CBDI? Not in the original analysis.... \n",
    "pow_df_depr = pow_df_depr[pow_df_depr['CBDI']!='med']\n",
    "\n",
    "bins = np.linspace(0,1,4)\n",
    "\n",
    "pow_df_depr['CV'] = pd.cut(pow_df_depr['valence'], bins=bins,\n",
    "                                                    labels=['neg', 'neutral', 'pos'])\n",
    "\n",
    "# Set categorical orders \n",
    "cat_type = CategoricalDtype(categories=['pos', 'neutral', 'neg'], ordered=True)\n",
    "pow_df_depr.CV = pow_df_depr.CV.astype(cat_type)\n",
    "cat_type = CategoricalDtype(categories=['Amy', 'Hipp'], ordered=True)\n",
    "pow_df_depr.region = pow_df_depr.region.astype(cat_type)\n",
    "cat_type = CategoricalDtype(categories=['low', 'high'], ordered=True)\n",
    "pow_df_depr.CBDI = pow_df_depr.CBDI.astype(cat_type)\n",
    "\n",
    "band = 'gamma'\n",
    "pow_df_depr = pow_df_depr[pow_df_depr.band==band]\n",
    "\n",
    "for region in ['Hipp', 'Amy']: \n",
    "    for depr in ['low', 'high']: \n",
    "\n",
    "        model_df = pow_df_depr[pow_df_depr.CBDI==depr]\n",
    "        model_df = model_df[model_df.region==region]\n",
    "\n",
    "        y = 'memory'\n",
    "        X = ['arousal', 'CV', 'power'] \n",
    "        Intx = ['power:arousal',\n",
    "                'power:CV']\n",
    "\n",
    "        rand_effect = 'subj'\n",
    "        categorical = ['CV']\n",
    "\n",
    "        # Drop nan data\n",
    "        model_df = model_df.dropna(subset=X)\n",
    "        label = (f\"{y}\" + \"_{}\"*len(X)).format(*X) + region + band + f'{depr}_BDI'\n",
    "\n",
    "        run_model(model_df, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical,\n",
    "                 chains=4, cores=4, tune=500, draws=1000, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04055cba-ad51-4d32-8413-1ad0936b9553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model 6: Effect of depression and power and arousal on memory and linear valence\n",
    "\n",
    "# BeckScores = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/Beck_Scores.csv')\n",
    "# BeckScores.rename(columns={'Subject Code':'subj'}, inplace=True)\n",
    "# BeckScores = BeckScores.drop(columns=['Unnamed: 0'])\n",
    "# pow_df_depr = pd.read_csv('/home1/salman.qasim/Salman_Project/FR_Emotion/LM_data_128_30_noIED.csv')\n",
    "# pow_df_depr = pow_df_depr.drop(columns=['Unnamed: 0'])\n",
    "# pow_df_depr = pow_df_depr.merge(BeckScores, on='subj')\n",
    "\n",
    "# for band in ['gamma']:\n",
    "#     pow_df_depr = pow_df_depr[pow_df_depr.band==band]\n",
    "        \n",
    "#     # Set up squared valence \n",
    "#     pow_df_depr['valence'] = pow_df_depr['valence'] - pow_df_depr['valence'].mean()\n",
    "# #     pow_df_depr['valence_squared'] = pow_df_depr['valence']**2\n",
    "    \n",
    "#     # Bin the BDI scores (this is ok because of clinical classification). \n",
    "#     pow_df_depr['CBDI'] = pd.qcut(pow_df_depr['BDI'], q=3,\n",
    "#                                                         labels=['low', 'med', 'high'])\n",
    "#     cat_type = CategoricalDtype(categories=['Amy', 'Hipp'], ordered=True)\n",
    "#     pow_df_depr.region = pow_df_depr.region.astype(cat_type)\n",
    "    \n",
    "#     # Should I get rid of the neutral CBDI? Not in the original analysis.... \n",
    "#     pow_df_depr = pow_df_depr[pow_df_depr['CBDI']!='med']\n",
    "\n",
    "\n",
    "#     cat_type = CategoricalDtype(categories=['low', 'high'], ordered=True)\n",
    "#     pow_df_depr.CBDI = pow_df_depr.CBDI.astype(cat_type)\n",
    "\n",
    "\n",
    "#     y = 'memory'\n",
    "#     X = ['arousal', 'valence', 'region', 'power', 'CBDI'] \n",
    "#     Intx = ['power:arousal', \n",
    "#             'power:valence',\n",
    "#             'power:CBDI',\n",
    "#             'power:region',\n",
    "#             'power:CBDI:valence',\n",
    "#             'power:CBDI:arousal',\n",
    "#             'power:CBDI:region',\n",
    "#             'power:CBDI:region:arousal',\n",
    "#             'power:CBDI:region:valence']\n",
    "    \n",
    "# #             'power:hemi:region:arousal',\n",
    "# #             'power:hemi:region:CV'\n",
    "\n",
    "#     rand_effect = 'subj'\n",
    "#     categorical = ['CBDI', 'region']\n",
    "\n",
    "#     # Drop nan data\n",
    "#     pow_df_depr = pow_df_depr.dropna(subset=X)\n",
    "\n",
    "#     run_model(pow_df_depr, y, X, Intx, rand_effect, rand_slopes=False, categorical=categorical,\n",
    "#              chains=4, cores=4, tune=500, draws=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c12480-103e-4215-a2ae-cbf12ffe01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out the HDI plot of all the fixed effects\n",
    "band='gamma'\n",
    "output_dir = '/home1/salman.qasim/Salman_Project/FR_Emotion/BayesModels'\n",
    "for region in ['Hipp', 'Amy']: \n",
    "    for depr in ['low', 'high']: \n",
    "        y = 'memory'\n",
    "        X = ['arousal', 'CV', 'power'] \n",
    "        label = (f\"{y}\" + \"_{}\"*len(X)).format(*X) + region + band + f'{depr}_BDI'\n",
    "        results = az.from_netcdf(f'{output_dir}/{label}_model')\n",
    "        axes = az.plot_forest(results,\n",
    "                               kind='ridgeplot',\n",
    "                               var_names=[f'^{x}' for x in X],\n",
    "                               filter_vars=\"regex\",\n",
    "                               colors='lightgray',\n",
    "                               combined=True,\n",
    "                               hdi_prob=0.95,\n",
    "                               figsize=(9, 7))\n",
    "        plt.vlines(0, plt.ylim()[0], plt.ylim()[1], color = 'black')\n",
    "        plt.xlim([-0.4, 0.4])\n",
    "        plt.savefig(join(output_dir, f'{label}_HDIplot.pdf'), dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d9a35-a965-4006-9f4a-936c124bdd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bambi_env",
   "language": "python",
   "name": "bambi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
